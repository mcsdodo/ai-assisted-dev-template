# Upstream Sync Analysis: 2026-01-06

**Date:** 2026-01-06
**Reference commit time (this template):** 2025-12-30 20:48:21 +0100
**Commits analyzed from upstream:** **30 commits** since that date (2026-01-02 to 2026-01-06)

---

## Executive Summary

The upstream project has evolved **significantly** since this template was created. In just 5 days, 30 commits show rapid iteration on agentic workflows:

### Key Additions
1. **Verification workflow** - `/verify` skill to ensure completeness before marking work done
2. **Iterative review skills** - code-review, plan-review, test-review with quality gates (max 4 iterations)
3. **Hooks system** - Automated enforcement (pre-commit test blocking, post-commit changelog reminders)
4. **Stronger completion discipline** - Explicit checklists, mandatory changelog updates
5. **CI/CD Integration** - GitHub Actions for automated testing
6. **E2E Testing Infrastructure** - WebdriverIO + tauri-driver integration tests

### Evolution Pattern Observed
The commits show a **meta-workflow**: using their own agentic tools to improve those tools:
- `docs(task-21): iteration 1-4 review` - Four iterations of review on agentic workflow improvements
- `docs: add agentic workflow improvements analysis` - Self-reflection on their process
- `feat: add Claude Code hooks and verify skill` - Implementing learnings

This "dogfooding" approach validates the patterns before we adopt them.

---

## Detailed Comparison

### 1. Skills Comparison

| Skill | Template | Upstream | Gap Analysis |
|-------|----------|----------|--------------|
| changelog-skill | Yes | Yes (localized categories) | Template is generic (good) |
| decision-skill | Yes | Yes | Equivalent |
| release-skill | Yes | Yes | Upstream has project-specific commands |
| task-plan-skill | Yes | Yes | Equivalent |
| **verify-skill** | **NO** | Yes | **MISSING - HIGH PRIORITY** |
| **code-review-skill** | **NO** | Yes (NEW) | **MISSING - NEW FEATURE** |
| **plan-review-skill** | **NO** | Yes (NEW) | **MISSING - NEW FEATURE** |
| **test-review-skill** | **NO** | Yes (NEW) | **MISSING - NEW FEATURE** |
| _templates folder | NO | Yes (empty) | Could be useful pattern |

### 2. Commands Comparison

| Command | Template | Upstream |
|---------|----------|----------|
| /changelog | Yes | Yes |
| /decision | Yes | Yes |
| /release | Yes | Yes |
| /task-plan | Yes | Yes |
| **/verify** | **NO** | Yes |

**Note:** Upstream recently added review skills but no explicit `/code-review`, `/plan-review`, `/test-review` commands - they're invoked via CLAUDE.md documentation.

### 3. Hooks System (ENTIRELY MISSING from template)

Upstream has a sophisticated hooks system:

**`.claude/settings.json`:**
```json
{
  "hooks": {
    "PreToolUse": [
      {
        "matcher": "Bash",
        "hooks": [
          {
            "type": "command",
            "command": "pwsh -NoProfile -File .claude/hooks/pre-commit.ps1",
            "timeout": 120000
          }
        ]
      }
    ],
    "PostToolUse": [
      {
        "matcher": "Bash",
        "hooks": [
          {
            "type": "command",
            "command": "pwsh -NoProfile -File .claude/hooks/post-commit-reminder.ps1",
            "timeout": 5000
          }
        ]
      }
    ]
  }
}
```

**Hook files:**
- `pre-commit.ps1` - Blocks commits if tests fail
- `post-commit-reminder.ps1` - Reminds to run /changelog after commits

**Gap:** Template has no hooks system. This is a powerful enforcement mechanism.

### 4. CLAUDE.md Differences

**Upstream additions we should consider:**

#### a) Task Completion Checklist
```markdown
### Task Completion Checklist

Before marking any task complete:
- [ ] Tests pass? (`npm run test:backend` or `npm run test:all`)
- [ ] Code committed with descriptive message?
- [ ] `/changelog` run to update [Unreleased]?
- [ ] Changelog committed?

For significant decisions during task:
- [ ] `/decision` run to record ADR/BIZ entry?
```

#### b) Mandatory Changelog Warning
```markdown
**MANDATORY FINAL STEP:** After completing any feature, fix, or change:
1. Commit all code changes
2. Run `/changelog` to update the [Unreleased] section
3. Commit the changelog update

**WARNING:** Do NOT mark a task as complete without updating the changelog.
```

#### c) Git Staging Discipline
```markdown
**Only commit files you changed in THIS session.** Before committing:
1. Run `git status` to see all modified files
2. Stage only files related to your current task
3. Do NOT include unrelated staged files from previous sessions

# Bad: stage everything blindly
git add -A  # Only use for releases
```

#### d) Skills Reference Table
```markdown
| Skill | When to Use | Purpose |
|-------|-------------|---------|
| `/task-plan` | Starting new feature | Create planning folder |
| `/decision` | Making architectural choices | Add entry to DECISIONS.md |
| `/changelog` | After completing any work | Update [Unreleased] section |
| `/verify` | Before claiming "done" | Run tests, check status |
| `/release` | Publishing new version | Bump, tag, push |
| `/plan-review` | Before coding | Review plan completeness |
| `/code-review` | After implementation | Review code quality |
| `/test-review` | After feature complete | Check test coverage |
```

#### e) Git Worktrees
```markdown
## Git Worktrees

Worktree directory: `.worktrees/` (project-local, gitignored)
```

### 5. Recent Commits Analysis (upstream: 30 commits since 2025-12-30)

#### Commit Themes

**Agentic Workflow Evolution (10 commits):**
- `feat: add Claude Code hooks and verify skill` - Core infrastructure
- `feat: add parameterized review skills (Option C)` - Iterative review system
- `docs(task-21): iteration 1-4 review` - Four refinement passes on workflow docs
- `docs: add agentic workflow improvements analysis` - Meta-analysis of their process

**Testing Infrastructure (8 commits):**
- `feat: add E2E integration testing infrastructure` - WebdriverIO + tauri-driver
- `ci: add GitHub Actions workflow for tests` - Automated CI/CD
- `test: add year carryover tests` / `test: add business logic tests for period rates`
- Multiple CI fixes for cross-platform support

**Code Quality (6 commits):**
- `refactor: split tests into separate files` - Test organization
- `refactor: replace Slovak terms with English in code` - Consistency
- Various fixes and documentation updates

**Releases (1 commit):**
- `chore: release v0.8.0`

#### Key Insight: Iterative Review Pattern

The `task-21` commits show exactly how they use their review skills:
1. **Iteration 1**: Major simplifications identified
2. **Iteration 2**: Refinements applied
3. **Iteration 3**: Edge case analysis
4. **Iteration 4**: Final polish

This 4-iteration pattern is baked into their review skills as a quality gate.

---

## Critical Learning: The 80/20 Principle

**From upstream task-21 final roadmap:**

> "Focus on automation that enforces quality, not comprehensive documentation."

Their original proposal included many items that were **deliberately eliminated**:
- ❌ Restructured CLAUDE.md
- ❌ Five separate skills (tdd, review, debug, pre-implementation)
- ❌ Multiple hooks
- ❌ Extensive cross-referencing

**Reason:** These either duplicate existing capabilities (superpowers already has review, TDD skills), add bureaucratic overhead, or lack enforcement mechanisms.

### What Actually Works (Their Validated Learnings)

| Item | Priority | Time | Rationale |
|------|----------|------|-----------|
| **Pre-commit test hook** | Critical | 1hr | Only thing that genuinely enforces TDD |
| **Post-commit changelog reminder** | High | 30min | Addresses most common workflow gap |
| **Verify-skill** | Medium | 30min | Checklist before marking done |
| **CLAUDE.md minor updates** | Low | 10min | Better visibility for pitfalls |

### Iterative Review Insights (task-23)

From their research synthesis:
- **3-5 iterations optimal** - Diminishing returns after 5
- **Severity categorization** - Critical/Important/Minor prevents treating nitpicks as blockers
- **Quality gates** - Early exit conditions prevent unnecessary cycles
- **Independent verification** - Don't trust implementer reports

**Implication for template:** The sophisticated review skills (code-review, plan-review, test-review) may be overkill for a baseline template. They're useful but the 80/20 approach suggests starting simpler.

---

## Revised Recommendations for Template

### ESSENTIAL (Adopt Now)

1. **Add verify-skill** - Generic verification checklist
   - Run tests (placeholder command)
   - Check git status
   - Verify changelog updated

2. **Add /verify command** - Point to verify-skill

3. **Add hooks scaffolding** - `.claude/settings.json` with documented placeholders
   - Pre-commit: test blocking (example, not enforced)
   - Post-commit: changelog reminder (example)

4. **Update CLAUDE.md** with:
   - Task Completion Checklist (generic)
   - Git staging discipline warning
   - Skills reference table
   - Worktrees convention mention

### CONSIDER (Maybe Later)

5. **Hooks example scripts** - Platform decision needed (PowerShell vs bash vs both)
   - These are project-specific (test commands vary)
   - Maybe just document the pattern in SETUP.md

6. **Review skills** - The sophisticated iterative review system
   - Superpowers already provides `superpowers:requesting-code-review`
   - Upstream added their own because they have project-specific needs
   - For template: document the pattern, don't duplicate superpowers

### SKIP (Not Template-Appropriate)

- ❌ TDD skill (superpowers has `superpowers:test-driven-development`)
- ❌ Debugging skill (superpowers has `superpowers:systematic-debugging`)
- ❌ Pre-implementation skill (covered by brainstorming + task-plan)
- ❌ Extensive cross-referencing systems

---

## Questions Resolved

| Question | Answer |
|----------|--------|
| Include review skills? | No - superpowers provides these, avoid duplication |
| Hooks cross-platform? | Provide structure + SETUP.md guidance, not scripts |
| Include actual hook scripts? | No - too project-specific, provide examples in docs |

---

## Implementation Checklist

### Files to Create
- [ ] `.claude/skills/verify-skill/SKILL.md`
- [ ] `.claude/commands/verify.md`

### Files to Update
- [ ] `CLAUDE.md` - Add completion checklist, git discipline, skills table, worktrees
- [ ] `.claude/SETUP.md` - Add hooks setup guidance
- [ ] `README.md` - Add /verify to commands table

### Optional/Later
- [ ] `.claude/settings.json` - Example structure (commented out or in SETUP.md)
- [ ] `.claude/hooks/` - Example scripts (if decided)

---

## Iteration 2: Concrete Drafts

### Draft: verify-skill/SKILL.md

```markdown
---
name: verify-skill
description: Use before claiming work is complete to verify all requirements are met
---

# Verification Before Completion

This skill ensures work is truly complete before marking it done.

## When to Apply

- Before marking a task as complete
- Before creating a PR
- Before claiming "done" to the user

## Verification Checklist

### Step 1: Run Tests

```bash
[TEST_COMMAND]
```

All tests must pass. If tests fail, fix them before proceeding.

### Step 2: Check Git Status

```bash
git status
```

Verify:
- All relevant changes are committed
- No unintended files are staged
- Working directory is clean (or only has intentional uncommitted changes)

### Step 3: Verify Changelog

Check that `CHANGELOG.md` [Unreleased] section includes an entry for this work.

If missing, run `/changelog` first.

### Step 4: Review CLAUDE.md Constraints

Quickly scan project's CLAUDE.md for any constraints that apply to this work.

## Quick Verification Script (Example)

```bash
# Run tests, show status, preview changelog
[TEST_COMMAND] && git status && head -20 CHANGELOG.md
```

## Related Skills

- **changelog-skill** - Update changelog if Step 3 fails
- **release-skill** - After verification, may proceed to release
```

### Draft: CLAUDE.md Additions

**Section: Task Completion Checklist** (add near end of file)

```markdown
## Task Completion Checklist

Before marking any task complete:

- [ ] Tests pass? (run your test command)
- [ ] Code committed with descriptive message?
- [ ] `/changelog` run to update [Unreleased]?
- [ ] Changelog committed?

For significant decisions made during task:
- [ ] `/decision` run to record ADR/BIZ entry?
```

**Section: Git Commit Guidelines** (add to existing conventions or create new section)

```markdown
## Git Commit Guidelines

**Stage only files from your current session.** Before committing:

1. Run `git status` to see all modified files
2. Stage only files related to your current task
3. Do NOT include unrelated files from previous sessions

```bash
# Good: stage specific files
git add src/feature.ts tests/feature.test.ts

# Avoid: staging everything blindly
git add -A  # Only use for releases or when ALL changes reviewed
```

**Exception:** `/release` uses `git add -A` because releases should include all pending changes.
```

**Section: Git Worktrees** (optional, add if project uses them)

```markdown
## Git Worktrees

For isolated feature work, use worktrees in `.worktrees/` (gitignored).
```

### Draft: SETUP.md Hooks Section

```markdown
## Hooks (Optional)

Claude Code supports hooks that run before/after tool execution. These can enforce workflows automatically.

### Example: Test Before Commit

Create `.claude/settings.json`:

```json
{
  "hooks": {
    "PreToolUse": [
      {
        "matcher": "Bash",
        "hooks": [
          {
            "type": "command",
            "command": "[YOUR_TEST_RUNNER_SCRIPT]",
            "timeout": 120000
          }
        ]
      }
    ]
  }
}
```

### Example: Changelog Reminder After Commit

```json
{
  "hooks": {
    "PostToolUse": [
      {
        "matcher": "Bash",
        "hooks": [
          {
            "type": "command",
            "command": "[YOUR_REMINDER_SCRIPT]",
            "timeout": 5000
          }
        ]
      }
    ]
  }
}
```

**Note:** Hook scripts are project-specific. See [Claude Code Hooks Documentation](https://docs.anthropic.com/en/docs/claude-code/hooks) for details.

### Writing Hook Scripts

Hook scripts receive JSON via stdin with tool information. They should:
- Return exit code 0 to allow the operation
- Return exit code 2 to block the operation
- Handle errors gracefully (don't block on script failures)
```

---

## Iteration 2: 80/20 Validation

| Proposed Change | Enforces Quality? | Worth Adding? |
|-----------------|-------------------|---------------|
| verify-skill | Yes - explicit checklist | ✅ Yes |
| /verify command | Yes - easy invocation | ✅ Yes |
| Task Completion Checklist in CLAUDE.md | Somewhat - reminder | ✅ Yes (small addition) |
| Git staging discipline | Yes - prevents mistakes | ✅ Yes (small addition) |
| Skills table in CLAUDE.md | No - already in README | ❌ Skip (duplication) |
| Worktrees in CLAUDE.md | No - nice to have | ⚠️ Optional |
| Hooks in SETUP.md | Yes - enables automation | ✅ Yes (documentation only) |

**Conclusion:** The essentials are minimal and focused. We're not over-adding.

---

## Iteration 3: Edge Cases and Refinements

### Edge Case Analysis

| Scenario | Current Draft Handling | Refinement Needed? |
|----------|------------------------|-------------------|
| Project has no tests | `[TEST_COMMAND]` placeholder | Add note: "Skip if no tests" |
| No CHANGELOG.md | Assumes it exists | Add conditional: "If using changelog..." |
| Superpowers available | Not mentioned | Add reference to `superpowers:verification-before-completion` |
| No git repo | Assumes git | Minor - templates assume git |

### Superpowers Integration

The template assumes superpowers is available (README mentions it). Our skills should complement, not duplicate:

| Our Skill | Superpowers Equivalent | Relationship |
|-----------|------------------------|--------------|
| verify-skill | `superpowers:verification-before-completion` | Complement - ours is simpler checklist |
| task-plan-skill | `superpowers:brainstorming` + `superpowers:writing-plans` | Ours orchestrates, superpowers does heavy lifting |
| decision-skill | None | Unique to template |
| changelog-skill | None | Unique to template |
| release-skill | None | Unique to template |

**Recommendation:** Add note to verify-skill: "For more rigorous verification, also invoke `superpowers:verification-before-completion`"

### CLAUDE.md Placement

Current structure:
1. Core Principle
2. Project Overview
3. Documentation Policy
4. ...
5. Slash Commands
6. **← Add: Task Completion Checklist here**
7. **← Add: Git Commit Guidelines here**
8. Code Conventions

### SETUP.md Updates Needed

Add to Quick Setup Checklist:
```markdown
- [ ] Customize `/verify` command test placeholder (if using tests)
```

### README.md Updates Needed

Add to Slash Commands table:
```markdown
| `/verify` | Run verification checks before marking work complete |
```

Add to "Copy As-Is" files:
```markdown
| `.claude/commands/verify.md` | `/verify` command |
| `.claude/skills/verify-skill/SKILL.md` | Verification workflow |
```

### Refined verify-skill Draft

Key refinements:
1. Add "Skip if N/A" notes for optional steps
2. Reference superpowers skill
3. Make changelog step conditional

```markdown
### Step 1: Run Tests (if applicable)

If project has tests:
```bash
[TEST_COMMAND]
```

All tests must pass. If tests fail, fix them before proceeding.

*Skip if project has no automated tests.*
```

### Consistency Checks

| Item | Pattern | Draft Follows? |
|------|---------|----------------|
| Skill frontmatter | `name:` + `description:` | ✅ Yes |
| Command format | 2 lines: description + "Use skill:" | ✅ Yes |
| Related Skills section | At end of skill | ✅ Yes |
| Placeholder format | `[PLACEHOLDER]` | ✅ Yes |

### Potential Issues Identified

1. **verify-skill references superpowers** - But superpowers is optional
   - **Fix:** Make reference conditional: "If available..."

2. **Hooks documentation mentions specific URLs** - URLs may change
   - **Fix:** Use generic reference or check current docs

3. **Git staging section uses TypeScript example** - Template is language-agnostic
   - **Fix:** Use generic file names: `src/feature.ext tests/feature.test.ext`

---

## Iteration 4: Final Implementation Plan

### Summary of Changes

Based on 30 commits of real-world evolution in upstream and their documented 80/20 learnings, here are the validated changes to implement:

### Final File List

| Action | File | Description |
|--------|------|-------------|
| **CREATE** | `.claude/skills/verify-skill/SKILL.md` | Verification checklist skill |
| **CREATE** | `.claude/commands/verify.md` | `/verify` command |
| **UPDATE** | `CLAUDE.md` | Add completion checklist + git guidelines |
| **UPDATE** | `.claude/SETUP.md` | Add hooks documentation + verify setup |
| **UPDATE** | `README.md` | Add /verify to commands + file index |

### Final Content: `.claude/skills/verify-skill/SKILL.md`

```markdown
---
name: verify-skill
description: Use before claiming work is complete to verify all requirements are met
---

# Verification Before Completion

This skill ensures work is truly complete before marking it done.

## When to Apply

- Before marking a task as complete
- Before creating a PR
- Before claiming "done" to the user

## Verification Checklist

### Step 1: Run Tests

If project has automated tests:

\`\`\`bash
[TEST_COMMAND]
\`\`\`

All tests must pass. If tests fail, fix them before proceeding.

*Skip if project has no automated tests.*

### Step 2: Check Git Status

\`\`\`bash
git status
\`\`\`

Verify:
- All relevant changes are committed
- No unintended files are staged
- Working directory is clean (or only has intentional uncommitted changes)

### Step 3: Verify Changelog

If project uses `CHANGELOG.md`:
- Check that `[Unreleased]` section includes an entry for this work
- If missing, run `/changelog` first

### Step 4: Review Constraints

Quickly scan project's `CLAUDE.md` for any constraints that apply to this work.

## Quick Verification Script (Example)

\`\`\`bash
# Run tests, show status, preview changelog
[TEST_COMMAND] && git status && head -20 CHANGELOG.md
\`\`\`

Customize `[TEST_COMMAND]` for your project (e.g., `npm test`, `pytest`, `cargo test`).

## Superpowers Integration

If `superpowers` is available, consider also invoking `superpowers:verification-before-completion` for more rigorous verification.

## Related Skills

- **changelog-skill** - Update changelog if Step 3 fails
- **release-skill** - After verification, may proceed to release
```

### Final Content: `.claude/commands/verify.md`

```markdown
Run verification checks before marking work complete.

Use skill: verify-skill
```

### Final Content: CLAUDE.md Additions

**Add after "Slash Commands" section:**

```markdown
## Task Completion Checklist

Before marking any task complete:

- [ ] Tests pass? (run your test command)
- [ ] Code committed with descriptive message?
- [ ] `/changelog` run to update [Unreleased]?
- [ ] Changelog committed?

For significant decisions made during task:
- [ ] `/decision` run to record ADR/BIZ entry?

## Git Commit Guidelines

**Stage only files from your current session.** Before committing:

1. Run `git status` to see all modified files
2. Stage only files related to your current task
3. Do NOT include unrelated files from previous sessions

\`\`\`bash
# Good: stage specific files
git add path/to/changed/file.ext path/to/test.ext

# Avoid: staging everything blindly
git add -A  # Only use for releases or when ALL changes reviewed
\`\`\`

**Exception:** `/release` uses `git add -A` because releases should include all pending changes.
```

### Final Content: SETUP.md Additions

**Add to Quick Setup Checklist:**

```markdown
- [ ] Customize `/verify` skill test command (if using tests)
```

**Add new section after existing content:**

```markdown
## Hooks (Optional)

Claude Code supports hooks that run before/after tool execution. These can enforce workflows automatically.

### Pre-Commit Test Hook

Block commits when tests fail:

\`\`\`json
// .claude/settings.json
{
  "hooks": {
    "PreToolUse": [
      {
        "matcher": "Bash",
        "hooks": [
          {
            "type": "command",
            "command": "[PATH_TO_YOUR_TEST_SCRIPT]",
            "timeout": 120000
          }
        ]
      }
    ]
  }
}
\`\`\`

### Post-Commit Changelog Reminder

Remind to update changelog after commits:

\`\`\`json
{
  "hooks": {
    "PostToolUse": [
      {
        "matcher": "Bash",
        "hooks": [
          {
            "type": "command",
            "command": "[PATH_TO_YOUR_REMINDER_SCRIPT]",
            "timeout": 5000
          }
        ]
      }
    ]
  }
}
\`\`\`

### Writing Hook Scripts

Hook scripts:
- Receive JSON via stdin with tool information
- Return exit code 0 to allow the operation
- Return exit code 2 to block the operation
- Should handle errors gracefully (don't block on script failures)

See [Claude Code Hooks Documentation](https://docs.anthropic.com/en/docs/claude-code/hooks) for full details.
```

### Final Content: README.md Updates

**Add to Slash Commands table:**

```markdown
| `/verify` | Run verification checks before marking work complete |
```

**Add to "Copy As-Is" files table:**

```markdown
| `.claude/commands/verify.md` | `/verify` command |
| `.claude/skills/verify-skill/SKILL.md` | Verification workflow |
```

---

## Implementation Order

1. Create verify-skill and command (new files, no conflicts)
2. Update README.md (add to tables)
3. Update CLAUDE.md (add new sections at end)
4. Update SETUP.md (add hooks documentation)

---

## What We're NOT Doing (And Why)

| Skipped Item | Reason |
|--------------|--------|
| Review skills (code-review, plan-review, test-review) | Superpowers provides these; avoid duplication |
| TDD skill | Superpowers has `superpowers:test-driven-development` |
| Debugging skill | Superpowers has `superpowers:systematic-debugging` |
| Actual hook scripts | Too project-specific; documented pattern instead |
| settings.json file | Project-specific; documented in SETUP.md |
| Skills table in CLAUDE.md | Already in README.md |

---

## Validation Against 80/20 Principle

✅ **Enforces quality:** verify-skill is an explicit checklist
✅ **Minimal additions:** Only 2 new files, 3 file updates
✅ **Documented not duplicated:** Hooks pattern documented, not prescribed
✅ **Complements superpowers:** References, doesn't replace
✅ **Battle-tested:** Based on upstream's 30-commit evolution

---

## Open Questions for User

1. **Worktrees mention:** Should we add the brief worktrees section to CLAUDE.md?
   - Pro: Useful convention for complex projects
   - Con: Not all projects need it

2. **Hook scripts examples:** Should we include example PowerShell/bash scripts in `.claude/hooks/`?
   - Pro: Easier to customize
   - Con: Platform-specific, needs maintenance

**Recommendation:** Start without these. Add if users request them.

---

## Addendum: Iterative Review Skills

User requested adding the iterative review skills that upstream developed. These add a **4-iteration quality gate pattern** on top of superpowers' code-reviewer.

### Why Add These?

| Superpowers | Iterative Review Skills |
|-------------|------------------------|
| Single-pass review | Max 4 iterations with quality gate |
| Manual re-review decision | Automatic loop until criteria met |
| No convergence tracking | Exit when no Critical/Important issues |

### Three Review Skills to Add

| Skill | Focus | Exit Criteria |
|-------|-------|---------------|
| `code-review-skill` | Code quality, correctness, best practices | Tests pass + no Critical/Important |
| `plan-review-skill` | Completeness, feasibility, clarity | No Critical/Important issues |
| `test-review-skill` | Coverage, edge cases, quality | 2 consecutive iterations with no new issues |

### Additional Files to Create

| File | Description |
|------|-------------|
| `.claude/skills/code-review-skill/SKILL.md` | Iterative code review workflow |
| `.claude/skills/plan-review-skill/SKILL.md` | Plan/design review workflow |
| `.claude/skills/test-review-skill/SKILL.md` | Test coverage review workflow |

### Final Content: `.claude/skills/code-review-skill/SKILL.md`

```markdown
---
name: code-review-skill
description: Use to review code implementations with iterative quality gates
---

# Iterative Code Review

Review code for quality, correctness, and best practices with up to 4 iterations.

## When to Apply

- After implementing a feature
- Before creating a PR
- After significant refactoring
- When code quality is uncertain

## Requirements

Before starting:
1. **Target**: File path or git range to review
2. **Reference**: Plan, spec, or requirements document

## Quality Gate

Exit when: **Tests pass + no Critical/Important issues**

## Severity Levels

| Level | Description | Action |
|-------|-------------|--------|
| **Critical** | Bugs, security issues, broken functionality | Must fix before proceeding |
| **Important** | Missing error handling, spec misalignment | Should fix before merge |
| **Minor** | Style, naming, small improvements | Note for later |

## Workflow

### Step 1: Gather Context

\`\`\`bash
# If reviewing git range
git diff [BASE_SHA]..[HEAD_SHA] --stat
git log [BASE_SHA]..[HEAD_SHA] --oneline

# Read reference document
\`\`\`

### Step 2: Run Tests (Baseline)

\`\`\`bash
[TEST_COMMAND]
\`\`\`

Tests must pass before review begins.

### Step 3: Create Progress File

Create `_code-review.md` to track iterations:

\`\`\`markdown
# Code Review Progress

**Target:** [file or git range]
**Reference:** [plan/spec document]

## Iteration 1
- [ ] Review complete
- Findings: ...
- Changes applied: ...
\`\`\`

### Step 4: Iterative Review Loop (Max 4)

For each iteration:

1. **Dispatch reviewer**: Use `superpowers:code-reviewer` agent with:
   - What was implemented
   - Reference document
   - Code target (files or git range)

2. **Categorize findings** by severity

3. **Fix Critical/Important issues**

4. **Re-run tests**: `[TEST_COMMAND]`

5. **Update progress file**

6. **Check exit criteria**:
   - Tests pass AND no Critical/Important issues? → Done
   - Otherwise → Next iteration (if < 4)

### Step 5: Final Assessment

Document in progress file:
- Summary of changes made
- Remaining Minor issues (if any)
- Readiness for merge

## Domain Checklist

- [ ] Tests pass?
- [ ] No obvious bugs?
- [ ] Error handling adequate?
- [ ] Security considerations addressed?
- [ ] Matches specification/requirements?
- [ ] No scope creep beyond requirements?
- [ ] Follows project patterns (see CLAUDE.md)?

## Example Usage

\`\`\`
Target: src/auth/login.ts
Reference: _tasks/05-auth-feature/02-plan.md

Iteration 1:
  Findings: [Critical] Missing input validation, [Minor] Inconsistent naming
  Fixed: Added validation
  Tests: Pass

Iteration 2:
  Findings: [Minor] Could add more specific error messages
  Assessment: Ready for merge (only Minor issues remain)
\`\`\`

## Related Skills

- **plan-review-skill** - Review plans before implementation
- **test-review-skill** - Review test coverage
- **verify-skill** - Quick verification checklist
```

### Final Content: `.claude/skills/plan-review-skill/SKILL.md`

```markdown
---
name: plan-review-skill
description: Use to review plans and designs before implementation
---

# Iterative Plan Review

Review plans for completeness, feasibility, and clarity with up to 4 iterations.

## When to Apply

- Before starting implementation
- After creating a task plan
- When reviewing design documents
- Before complex refactoring

## Requirements

Before starting:
1. **Target**: Plan or design document path
2. **Reference**: (Optional) Requirements or constraints

## Quality Gate

Exit when: **No Critical/Important issues remain**

## Review Dimensions

| Dimension | Questions |
|-----------|-----------|
| **Completeness** | All requirements addressed? Tasks identified? Edge cases considered? |
| **Feasibility** | Tasks achievable? Hidden complexities? Dependencies identified? |
| **Clarity** | Can implementer follow without ambiguity? Specific file paths? Verification steps? |
| **Scope** | YAGNI respected? No unnecessary additions? No duplication? |

## Severity Levels

| Level | Description | Action |
|-------|-------------|--------|
| **Critical** | Missing requirements, impossible tasks | Must fix before implementation |
| **Important** | Unclear steps, missing verification | Should fix before starting |
| **Minor** | Could be clearer, minor improvements | Note for consideration |

## Workflow

### Step 1: Read Target Document

Thoroughly read the plan/design document.

### Step 2: Create Progress File

Create `_plan-review.md`:

\`\`\`markdown
# Plan Review Progress

**Target:** [plan document path]
**Reference:** [requirements, if any]

## Iteration 1
- [ ] Review complete
- Findings: ...
- Changes applied: ...
\`\`\`

### Step 3: Iterative Review Loop (Max 4)

For each iteration:

1. **Review against dimensions**: Completeness, Feasibility, Clarity, Scope

2. **Categorize findings** by severity

3. **Fix Critical/Important issues** in the plan

4. **Update progress file**

5. **Check exit criteria**:
   - No Critical/Important issues? → Ready for implementation
   - Otherwise → Next iteration (if < 4)

### Step 4: Final Assessment

Document:
- Plan readiness for implementation
- Any caveats or assumptions
- Remaining Minor issues

## Domain Checklist

- [ ] All requirements mapped to tasks?
- [ ] Specific file paths included?
- [ ] Verification steps for each task?
- [ ] Tasks in logical order?
- [ ] No scope creep?
- [ ] Complexity appropriate?

## Example Usage

\`\`\`
Target: _tasks/08-feature/02-plan.md
Reference: _tasks/08-feature/01-task.md

Iteration 1:
  Findings: [Important] Step 3 missing file paths, [Minor] Could add time estimates
  Fixed: Added specific paths to Step 3

Iteration 2:
  Findings: [Minor] Consider adding rollback section
  Assessment: Ready for implementation
\`\`\`

## Related Skills

- **task-plan-skill** - Create the plans this skill reviews
- **code-review-skill** - Review implementation after coding
```

### Final Content: `.claude/skills/test-review-skill/SKILL.md`

```markdown
---
name: test-review-skill
description: Use to review test coverage for completeness and quality
---

# Iterative Test Review

Review test coverage for completeness, edge cases, and quality.

## When to Apply

- After implementing a feature
- Before release
- When adding tests to existing code
- Periodic test health checks

## Requirements

Before starting:
1. **Target**: Code module/file to analyze
2. **Reference**: (Optional) Business rules or requirements

## Quality Gate

Exit when: **2 consecutive iterations with no new issues** (convergence)

## Review Focus Areas

| Area | Questions |
|------|-----------|
| **Coverage** | All functions tested? All branches covered? |
| **Edge Cases** | Boundary conditions? Empty inputs? Error paths? |
| **Quality** | Tests verify real logic (not just mocks)? Independent? Meaningful assertions? |
| **Business Logic** | Business rules validated? Calculations verified? |

## Severity Levels

| Level | Description | Action |
|-------|-------------|--------|
| **Critical** | Untested critical path, missing error handling tests | Must add |
| **Important** | Missing edge cases, weak assertions | Should add |
| **Minor** | Could improve test names, minor gaps | Note for later |

## Workflow

### Step 1: Locate Test Files

\`\`\`bash
# Find tests for the target module
# Adjust pattern for your project structure
find . -name "*test*" -o -name "*spec*" | grep -i [module_name]
\`\`\`

### Step 2: Create Progress File

Create `_test-review.md`:

\`\`\`markdown
# Test Review Progress

**Target:** [code module path]
**Reference:** [business rules, if any]

## Iteration 1
- [ ] Review complete
- Findings: ...
- Tests added: ...
\`\`\`

### Step 3: Iterative Review Loop (Max 4)

For each iteration:

1. **Analyze coverage**: Map functions to tests

2. **Identify gaps**: Missing tests, edge cases, error paths

3. **Evaluate quality**: Real logic tested? Independent? Meaningful?

4. **Add/improve tests** for Critical/Important findings

5. **Run tests**: `[TEST_COMMAND]`

6. **Update progress file**

7. **Check convergence**:
   - 2 iterations with no new issues? → Done
   - New issues found? → Continue (if < 4)

### Step 4: Final Assessment

Document:
- Coverage summary
- Tests added
- Remaining gaps (if any)
- Test health assessment

## Domain Checklist

- [ ] Critical business logic has tests?
- [ ] Edge cases covered (empty, null, boundary)?
- [ ] Error scenarios tested?
- [ ] Tests are independent (no order dependency)?
- [ ] Assertions are meaningful (not just "no error")?
- [ ] No mock-only tests (testing real behavior)?

## Example Usage

\`\`\`
Target: src/calculations.ts
Reference: docs/business-rules.md

Iteration 1:
  Findings: [Critical] No tests for negative inputs, [Important] Missing boundary test
  Tests added: testNegativeInput(), testBoundaryValues()

Iteration 2:
  Findings: [Minor] Could add performance test
  Convergence: No new Critical/Important

Assessment: Coverage adequate for release
\`\`\`

## Related Skills

- **code-review-skill** - Review implementation alongside tests
- **verify-skill** - Quick pre-completion verification
```

### Updated Implementation Checklist

**Files to Create:**
- [ ] `.claude/skills/verify-skill/SKILL.md`
- [ ] `.claude/commands/verify.md`
- [ ] `.claude/skills/code-review-skill/SKILL.md`
- [ ] `.claude/skills/plan-review-skill/SKILL.md`
- [ ] `.claude/skills/test-review-skill/SKILL.md`

**Files to Update:**
- [ ] `CLAUDE.md` - Add completion checklist + git guidelines
- [ ] `.claude/SETUP.md` - Add hooks documentation
- [ ] `README.md` - Add /verify + review skills to tables

### Updated README.md Content

**Add to "Copy As-Is" files table:**

```markdown
| `.claude/commands/verify.md` | `/verify` command |
| `.claude/skills/verify-skill/SKILL.md` | Verification workflow |
| `.claude/skills/code-review-skill/SKILL.md` | Iterative code review |
| `.claude/skills/plan-review-skill/SKILL.md` | Plan/design review |
| `.claude/skills/test-review-skill/SKILL.md` | Test coverage review |
```

**Note:** Review skills don't need `/` commands - they're invoked via skill name or referenced in CLAUDE.md documentation.
